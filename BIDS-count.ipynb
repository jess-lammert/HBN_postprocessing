{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd2e717-d56c-4a5e-8a18-4d155d3f78c3",
   "metadata": {},
   "source": [
    "Description: The purpose of this script is to summarize the content of a BIDS input directory in order to quantify the number of T1w, fieldmap, and functional files present and later remove those participants without the desired files from the fmriprep outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975ba74f-cdc9-4fed-afe3-668963e6c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469eca72-13d5-41e1-b41b-d52367750861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to run .py from command line\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='Sorts a BIDS data directory and give a summary of T1w, fieldmap, and fMRI data.')\n",
    "\n",
    "#parser.add_argument('--bids_dir', help='Path to the bids directory', type=str)\n",
    "#parser.add_argument('--pp_out', help='Out put path where you want the summary tables to be saved', type=str)\n",
    "                    \n",
    "#args = parser.parse_args()\n",
    "#bids_dir = args.bids_dir\n",
    "#pp_out = args.pp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c205afa-b841-49cd-989a-fb082b562d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define directories for testing\n",
    "\n",
    "bids_dir = '/cifs/butler/HBN_data/TD_test_set' #contains unzipped input files in BIDS format\n",
    "pp_out = '/cifs/butler/HBN_data/preprocessing/postprocessing_outputs' #save .csv here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cd241d-ce19-4930-9de7-11679df39cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions\n",
    "\n",
    "def list_directories(path, *keywords):\n",
    "    os.chdir(path)\n",
    "    dirs = []\n",
    "    for keyword in keywords:\n",
    "        dirs.extend([f for f in glob.glob(keyword) if os.path.isdir(f)])\n",
    "    return [os.path.basename(d) for d in dirs] #returns list of directories in given folder\n",
    "\n",
    "def list_files(path, *keywords): #keyword is type of file (e.g., \"*T1w.nii.gz*\", \"*bold.nii.gz*\", \"*fMRI_epi.nii.gz*\")\n",
    "    os.chdir(path)\n",
    "    files = []\n",
    "    for keyword in keywords:\n",
    "        files.extend(glob.glob(keyword))\n",
    "    return [os.path.basename(file) for file in files] #returns list of files in given directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f7e029-eafe-4be5-87fa-16decf79c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_directories = list_directories(bids_dir, \"sub*\")\n",
    "\n",
    "dict_list = [] #create list to contain individual subject dictionaries \n",
    "\n",
    "for i, sub in enumerate(sub_directories): #for each subject directory\n",
    "    content = list_directories(bids_dir + '/' + sub, '*') #gets data folders in each subject directory\n",
    "    sub_dict = {'number': i, 'id': sub} #initialize dictionary for each subject\n",
    "    t1_count = 0\n",
    "    func_count = 0\n",
    "    fmap_count = 0\n",
    "    \n",
    "    for c in content: #check/quantify content in each subject's subfolders\n",
    "        if c == 'anat':\n",
    "            T1 = list_files(bids_dir + '/' + sub + '/' + c, '*T1w.nii.gz*')\n",
    "            t1_count = len(T1)\n",
    "            sub_dict['t1'] = 'yes'\n",
    "            sub_dict['t1_files'] = t1_count\n",
    "        elif c == 'func':\n",
    "            func = list_files(bids_dir + '/' + sub + '/' + c, '*bold.nii.gz*')\n",
    "            func_count = len(func)\n",
    "            sub_dict['func'] = 'yes'\n",
    "            sub_dict['func_files'] = func_count\n",
    "        elif c == 'fmap':\n",
    "            fmap = list_files(bids_dir + '/' + sub + '/' + c, '*fMRI_epi.nii.gz*')\n",
    "            fmap_count = len(fmap)\n",
    "            sub_dict['fmap'] = 'yes'\n",
    "            sub_dict['fmap_files'] = fmap_count         \n",
    "    \n",
    "    #if no content (values unchanged from initialization)\n",
    "    if t1_count == 0:\n",
    "        sub_dict['t1'] = 'no'\n",
    "        sub_dict['t1_files'] = 0\n",
    "    if func_count == 0:\n",
    "        sub_dict['func'] = 'no'\n",
    "        sub_dict['func_files'] = 0\n",
    "    if fmap_count == 0:\n",
    "        sub_dict['fmap'] = 'no'\n",
    "        sub_dict['fmap_files'] = 0\n",
    "    \n",
    "    dict_list.append(sub_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8697f8e5-4740-4493-9c51-886999bc04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_list)\n",
    "df.to_csv(pp_out+'/BIDS-count_all.csv', sep=',', index=False)\n",
    "\n",
    "#get df of participants with no T1 OR fmaps to exclude\n",
    "df_exclude = df[(df[\"t1_files\"] == 0) | (df[\"fmap_files\"] == 0)]\n",
    "df_exclude.to_csv(pp_out+'/BIDS-count_exclude.csv', sep=',', index=False)\n",
    "\n",
    "#get included (inverse of above, df of all-df exclude)\n",
    "df_include = df[~df['id'].isin(df_exclude[\"id\"])]\n",
    "df_include.to_csv(pp_out+'/BIDS-count_include.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
